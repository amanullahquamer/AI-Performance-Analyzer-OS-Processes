{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea17f3b3-78dd-4a7e-ba8c-0044e6c623d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-22 19:09:57.502 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-22 19:09:59.669 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-04-22 19:09:59.671 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-22 19:09:59.672 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-22 19:09:59.673 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-22 19:10:00.020 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-22 19:10:00.022 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-22 19:10:00.023 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-22 19:10:00.025 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-22 19:10:03.884 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-22 19:10:03.885 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-22 19:10:03.886 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-22 19:10:03.887 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import streamlit as st\n",
    "\n",
    "def extract_syscall_tokens(file_contents):\n",
    "    \"\"\"\n",
    "    Extracts syscall tokens from a system log file.\n",
    "    Only lines with \"SYSCALL\" are used.\n",
    "    \"\"\"\n",
    "    tokens = []\n",
    "    for line in file_contents.splitlines():\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        parts = line.split(',')\n",
    "        if len(parts) < 3:\n",
    "            continue\n",
    "        if parts[1].strip().upper() == \"SYSCALL\":\n",
    "            tokens.append(parts[2].strip())\n",
    "    return tokens\n",
    "\n",
    "def load_training_data(filename):\n",
    "    \"\"\"\n",
    "    Reads the file and returns the entire list of syscall tokens.\n",
    "    \"\"\"\n",
    "    with open(filename, 'r') as f:\n",
    "        contents = f.read()\n",
    "    return extract_syscall_tokens(contents)\n",
    "\n",
    "TRAINING_FILE = \"001_NORMAL_Flight.txt\"\n",
    "if not os.path.exists(TRAINING_FILE):\n",
    "    st.error(f\"Training file '{TRAINING_FILE}' not found!\")\n",
    "    st.stop()\n",
    "\n",
    "syscall_tokens = load_training_data(TRAINING_FILE)\n",
    "st.write(\"Total SYSCALL tokens extracted:\", len(syscall_tokens))\n",
    "\n",
    "# Tokenize the entire token list\n",
    "tokenizer = Tokenizer(lower=False, split=' ')\n",
    "tokenizer.fit_on_texts([\" \".join(syscall_tokens)])\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "st.write(\"Vocabulary size:\", vocab_size)\n",
    "\n",
    "# Instead of generating all subsequences, use a fixed-length sliding window.\n",
    "window_size = 20  # You can adjust this parameter\n",
    "step_size = 1    # You can increase this to reduce the number of samples\n",
    "\n",
    "all_tokens = tokenizer.texts_to_sequences([\" \".join(syscall_tokens)])[0]\n",
    "input_sequences = []\n",
    "labels = []\n",
    "for i in range(window_size, len(all_tokens), step_size):\n",
    "    input_sequences.append(all_tokens[i-window_size:i])\n",
    "    labels.append(all_tokens[i])\n",
    "\n",
    "# No need to pad if each sequence is exactly window_size length.\n",
    "# But in case the last sequence is shorter, pad it.\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=window_size, padding='pre')\n",
    "labels = to_categorical(labels, num_classes=vocab_size)\n",
    "\n",
    "st.write(\"Number of training samples:\", len(input_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e87f6e50-c18e-4ed6-a5ad-9c144c605209",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2025-04-12 18:01:39.771 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-12 18:01:39.772 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-12 18:01:39.773 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-12 18:01:39.775 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# Section 2: Model Building and Training\n",
    "# =============================================================================\n",
    "MODEL_PATH = \"syscall_lstm_model.h5\"\n",
    "EMBEDDING_DIM = 10\n",
    "\n",
    "def build_model(vocab_size, max_seq_length, embedding_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_seq_length))\n",
    "    model.add(Masking(mask_value=0.0))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dense(vocab_size, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    model = load_model(MODEL_PATH)\n",
    "    st.write(\"Loaded pre-trained model.\")\n",
    "else:\n",
    "    st.write(\"Training LSTM model... (this may take a while)\")\n",
    "    model = build_model(vocab_size, max_seq_length, EMBEDDING_DIM)\n",
    "    model.fit(input_sequences, labels, epochs=5, batch_size=64, verbose=1)\n",
    "    model.save(MODEL_PATH)\n",
    "    st.write(\"Model trained and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71bda872-8917-4388-8c87-d8b7f373dcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 3: Optimization Engine Functions\n",
    "\n",
    "cache = {}  # Global cache for predictive caching\n",
    "\n",
    "def predictive_cache(syscall):\n",
    "    \"\"\"\n",
    "    Simulate execution and caching of a system call.\n",
    "    \"\"\"\n",
    "    if syscall in cache:\n",
    "        st.write(f\"[Cache Hit] {syscall}: {cache[syscall]}\")\n",
    "        return cache[syscall]\n",
    "    else:\n",
    "        result = f\"Executed {syscall}\"\n",
    "        cache[syscall] = result\n",
    "        st.write(f\"[Caching] {syscall}\")\n",
    "        return result\n",
    "\n",
    "def adaptive_reorder(sequence, model, tokenizer, max_seq_length, threshold=0.6):\n",
    "    \"\"\"\n",
    "    Use the LSTM model to predict the next syscall.\n",
    "    If the prediction probability exceeds the threshold, prefetch that syscall.\n",
    "    \"\"\"\n",
    "    token_seq = tokenizer.texts_to_sequences([\" \".join(sequence)])[0]\n",
    "    token_seq = pad_sequences([token_seq], maxlen=max_seq_length, padding='pre')\n",
    "    prediction = model.predict(token_seq, verbose=0)\n",
    "    predicted_token = np.argmax(prediction, axis=1)[0]\n",
    "    predicted_prob = np.max(prediction)\n",
    "    inv_map = {v: k for k, v in tokenizer.word_index.items()}\n",
    "    predicted_call = inv_map.get(predicted_token, None)\n",
    "    if predicted_call and predicted_prob >= threshold:\n",
    "        st.write(f\"[Prefetch] Predicted '{predicted_call}' with probability {predicted_prob:.2f}\")\n",
    "        predictive_cache(predicted_call)\n",
    "    return sequence\n",
    "\n",
    "def batch_process(sequence):\n",
    "    \"\"\"\n",
    "    Group consecutive identical syscalls.\n",
    "    Returns a list of tuples: (syscall, count)\n",
    "    \"\"\"\n",
    "    batched = []\n",
    "    i = 0\n",
    "    while i < len(sequence):\n",
    "        count = 1\n",
    "        while i + 1 < len(sequence) and sequence[i+1] == sequence[i]:\n",
    "            count += 1\n",
    "            i += 1\n",
    "        batched.append((sequence[i], count))\n",
    "        i += 1\n",
    "    return batched\n",
    "\n",
    "def process_sequence(sequence, model, tokenizer, max_seq_length):\n",
    "    \"\"\"\n",
    "    Process a given syscall sequence:\n",
    "      - Apply adaptive reordering (prefetch next call).\n",
    "      - Batch process consecutive calls.\n",
    "      - Execute each call via predictive caching.\n",
    "    \"\"\"\n",
    "    st.write(\"=== Processing Sequence ===\")\n",
    "    st.write(\"Original sequence:\", sequence)\n",
    "    sequence = adaptive_reorder(sequence, model, tokenizer, max_seq_length)\n",
    "    st.write(\"After adaptive reordering:\", sequence)\n",
    "    batched = batch_process(sequence)\n",
    "    st.write(\"Batched sequence:\", batched)\n",
    "    results = []\n",
    "    for syscall, count in batched:\n",
    "        result = predictive_cache(syscall)\n",
    "        results.extend([result] * count)\n",
    "    st.write(\"Execution results:\", results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6963caef-d470-48d8-9efe-8fa72ff7c174",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-12 18:01:29.606 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-12 18:01:29.608 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-12 18:01:29.609 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-12 18:01:29.611 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-12 18:01:29.612 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-12 18:01:29.614 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-12 18:01:29.615 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-12 18:01:29.616 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-12 18:01:29.618 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-12 18:01:29.619 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-12 18:01:29.620 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-12 18:01:29.621 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-12 18:01:29.622 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-12 18:01:29.623 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-12 18:01:29.624 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-12 18:01:29.625 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-12 18:01:29.626 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-12 18:01:29.627 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-12 18:01:29.627 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-04-12 18:01:29.628 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "# Section 4: Streamlit User Interface\n",
    "# =============================================================================\n",
    "st.title(\"AI-Powered System Call Optimizer\")\n",
    "st.markdown(\"\"\"\n",
    "This application uses an LSTM-based model to learn patterns in system call logs.\n",
    "You can either upload a new log file (with the same format) or enter a custom\n",
    "system call sequence (syscall codes only, space-separated).\n",
    "\"\"\")\n",
    "\n",
    "# Option to upload a new system log file\n",
    "uploaded_file = st.file_uploader(\"Upload a system log file\", type=[\"txt\"])\n",
    "if uploaded_file is not None:\n",
    "    file_contents = uploaded_file.getvalue().decode(\"utf-8\")\n",
    "    # Extract tokens from the uploaded file\n",
    "    new_tokens = extract_syscall_tokens(file_contents)\n",
    "    st.write(\"Uploaded file contains\", len(new_tokens), \"SYSCALL tokens.\")\n",
    "    # Display the first 20 tokens for reference\n",
    "    st.write(\"First 20 tokens:\", new_tokens[:20])\n",
    "    # Process the entire sequence as one session\n",
    "    st.markdown(\"### Processing Uploaded System Log\")\n",
    "    process_sequence(new_tokens, model, tokenizer, max_seq_length)\n",
    "\n",
    "# Or, allow manual input of a system call sequence\n",
    "manual_input = st.text_input(\"Or enter a custom system call sequence (space-separated)\", \"0x53 0xe7 0xf 0x10\")\n",
    "if st.button(\"Optimize Manual Sequence\"):\n",
    "    user_seq = manual_input.split()\n",
    "    st.markdown(\"### Processing Manual Sequence\")\n",
    "    process_sequence(user_seq, model, tokenizer, max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c77eb991-59bd-4d7e-b0dd-820d9ffe6e95",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (507122745.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[15], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    streamlit run app.py\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "streamlit run app.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7e18d2-2504-4d9b-a9ee-7bd016585701",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
